**How the Gradient-Based Global Pooling Visualization Works:**

The script `analyze_adaface_global_attention.py` computes gradients of a scalar loss function with respect to the pre-pooling feature map (7×7×512) to visualize how AdaFace's global pooling operation treats spatial locations. Specifically, it: (1) extracts the 7×7×512 feature map F before global pooling, (2) passes it through the output_layer (which contains AdaptiveAvgPool2d((1,1)) to get a 512-dim embedding z, (3) applies L2 normalization to z, (4) defines a scalar loss L = ||z||² (sum of squared embedding values), (5) computes gradients ∂L/∂F via backpropagation, and (6) aggregates gradients across channels (mean of absolute gradients) to produce a 7×7 spatial gradient map. The theoretical expectation is that because global average pooling computes z_c = (1/49) * Σ_{i,j} F_{c,i,j}, the gradient ∂L/∂F_{c,i,j} = (1/49) * ∂L/∂z_c should be spatially constant within each channel, resulting in a uniform gradient map. However, the actual results show non-uniform gradients (higher in central facial regions, lower at edges), which could indicate: (a) the L2 normalization step after pooling introduces non-linearity that breaks the uniform gradient property, (b) the feature map F itself has spatially varying magnitudes that affect gradient magnitudes even if the pooling operation is uniform, (c) there may be a bug in the gradient computation (e.g., not properly isolating the pooling operation from normalization), or (d) the loss function choice (||z||²) may not be appropriate for demonstrating uniform pooling. The key question is whether this non-uniformity reflects the pooling operation itself or artifacts from normalization/non-linearities downstream of pooling.
