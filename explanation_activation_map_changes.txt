**What I Changed in the AdaFace Global Attention Visualization Script:**

**1. Replaced Gradient-Based Method with Simple Activation Averaging:**

**OLD APPROACH (Gradient-Based):**
- Computed gradients of a scalar loss (||embedding||²) w.r.t. the pre-pooling feature map
- Required backpropagation, gradient computation, and more complex logic
- Goal: Show that gradients are spatially uniform (proving global pooling treats all locations equally)
- Problem: Results showed non-uniform gradients (higher in center, lower at edges), which didn't clearly prove global pooling

**NEW APPROACH (Activation Averaging):**
- Simply extracts the 7×7×512 feature maps before global pooling
- Takes absolute values: `x.abs()` to get magnitude of activations
- Averages across all 512 channels: `.mean(dim=1)` to get a single 7×7 spatial map
- Much simpler: no gradients, no backprop, just direct feature map analysis

**2. Key Code Changes:**

**Function Name:**
- OLD: `compute_global_pooling_focus_map()` (gradient-based)
- NEW: `compute_global_pooling_activation_map()` (activation-based)

**Implementation:**
```python
# OLD (gradient-based):
x = x.detach().requires_grad_(True)  # Make leaf tensor
embedding = model.output_layer(x)
loss = (embedding ** 2).sum()
loss.backward()
grad_map = x.grad.abs().mean(dim=1)[0]  # Gradient magnitudes

# NEW (activation-based):
x = model.input_layer(image_tensor.to(device))
for layer in model.body:
    x = layer(x)
activation_map = x.abs().mean(dim=1)[0]  # Direct activation magnitudes
```

**3. What This New Approach Shows:**

- **All regions have activations**: The 7×7 map shows that feature maps have non-zero values across all spatial locations
- **Global pooling aggregates everything**: Since all locations have activations, global pooling (AdaptiveAvgPool2d) averages information from the entire face
- **Contrast with QAConv**: Unlike QAConv which only matches visible regions (via occlusion weighting), AdaFace processes all regions and pools them together

**4. Why This Is Better:**

- **Simpler**: No need for gradients or backpropagation
- **More direct**: Shows actual feature activations, not derivative information
- **Clearer interpretation**: Activation map directly shows "where the model processes information"
- **Proves the point**: If all 7×7 locations have activations, then global pooling must aggregate all of them

**5. Visualization Output:**

The script now produces a heatmap showing:
- **High activation** (green): Regions with strong feature responses
- **Low activation** (red): Regions with weaker feature responses
- **Key insight**: Even if some regions have stronger activations, ALL regions contribute to the final embedding via global pooling

**6. Mathematical Interpretation:**

- Feature map: F ∈ ℝ^(512×7×7) - 512 channels, 7×7 spatial locations
- Activation map: A = mean(|F|, dim=0) ∈ ℝ^(7×7) - average absolute activation per spatial location
- Global pooling: z = AdaptiveAvgPool2d(F) = mean(F, dim=(2,3)) ∈ ℝ^512 - averages all 7×7 locations
- The activation map A shows that all 49 locations have non-zero contributions before pooling

**7. Updated Labels:**

- Colorbar now says "AdaFace Feature Map Activations" instead of "Gradient Map"
- Subtitle: "Average absolute values - all regions contribute to global pooling"
- This makes it clear we're visualizing activations, not gradients
